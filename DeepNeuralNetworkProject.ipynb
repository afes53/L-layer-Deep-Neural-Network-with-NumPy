{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# L-layer deep neural network with numpy (no tensorflow)\n",
    "\n",
    "This code implements a deep neural network from scratch using NumPy. It trains a multi-layer neural network on a given dataset to perform classification tasks.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c95b8a08c6e2d6a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Libraries and Load Data:\n",
    "\n",
    "Our dataset is originally in a row-wise format, where each row represents an image, and each column contains the pixel values for that image. To process this data correctly, we need to transpose the dataset so that each column represents an image, and each row contains the pixel values. After transposing, we then convert the data into a NumPy array for further processing\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85128d1a95cfc8ab"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samet\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "text/plain": "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T12:35:57.984687Z",
     "start_time": "2024-06-27T12:35:53.183558700Z"
    }
   },
   "id": "2e7c1c42ea87dc4f",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1837fba62e136e8c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T12:36:02.786393Z",
     "start_time": "2024-06-27T12:36:01.927057100Z"
    }
   },
   "outputs": [],
   "source": [
    "train = df.to_numpy() \n",
    "np.random.shuffle(train) # shuffle the dataset\n",
    "train = train.T # take transpose of the dataset to make it columnwise\n",
    "y = train[0]\n",
    "x = train[1:]\n",
    "x = x / np.max(x) # Normalizes the feature values"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split Data into Training and Test Sets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dda41b52ef8631a8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_len = int(len(y)*0.8)\n",
    "y_train = y[:train_len]\n",
    "y_test = y[train_len:]\n",
    "x_train = x[:,:train_len]\n",
    "x_test = x[:,train_len:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T12:36:20.849846900Z",
     "start_time": "2024-06-27T12:36:20.836799700Z"
    }
   },
   "id": "3071c3bd63ad5e56",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize Network Parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d648493d62636b0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_size = x_train.shape[0]\n",
    "output_size = np.unique(y).shape[0]\n",
    "layer_dims = [input_size, 10, 5, output_size]\n",
    "n_samples = x_train.shape[1]\n",
    "activations = [\"relu\",\"relu\",\"softmax\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T12:49:05.053569200Z",
     "start_time": "2024-06-27T12:49:05.043063800Z"
    }
   },
   "id": "597d525dbef6822e",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Functions\n",
    "\n",
    "These functions are defined to initialize parameters, compute activations, forward propagate inputs through the network, compute losses, backpropagate errors, update parameters, and compute accuracy.\n",
    "\n",
    "The forward propagation in a neural network involves matrix multiplication to compute the activations of the current layer:\n",
    "\n",
    "z[l] = W[l] * A[l-1] + b[l]\n",
    "\n",
    "- Z[l] is the linear combination of the inputs (before applying the activation function) for layer l.\n",
    "- W[l] is the weight matrix of shape (layer_dims[l], layer_dims[l-1]).\n",
    "- A[l-1] is the activation from the previous layer (layer l-1), which has a shape (layer_dims[l-1], number_of_examples).\n",
    "- b[l] is the bias vector for layer l, which is added to each column of W[l] * A[l-1].\n",
    "\n",
    "So the shape of the W[l] must be (layer_dims[l], layer_dims[l-1])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c101e30c1eb81584"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    for l in range(1, L):\n",
    "        parameters[f'W{l}'] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
    "        parameters[f'b{l}'] = np.zeros((layer_dims[l], 1))\n",
    "    return parameters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T12:36:27.245660400Z",
     "start_time": "2024-06-27T12:36:27.237648500Z"
    }
   },
   "id": "f715a8e9e785b89a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    exp = np.exp(Z)\n",
    "    return exp / np.sum(exp, axis=0, keepdims=True)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(z, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T16:25:13.437438800Z",
     "start_time": "2024-06-28T16:25:13.412427Z"
    }
   },
   "id": "8a9f8cac80f04c39",
   "execution_count": 194
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def loss_function(A,Y):\n",
    "    m = Y.shape[1]\n",
    "    loss = np.sum(Y * np.log(A)) / -m\n",
    "    loss = np.squeeze(loss)\n",
    "    return loss\n",
    "\n",
    "def binary_cross_entropy_loss(A,Y):\n",
    "    m = Y.shape[1]\n",
    "    loss = np.sum(-Y * np.log(A) + (1 - Y) * np.log(1 - A)) / -m\n",
    "    loss = np.squeeze(loss)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T16:28:00.845489Z",
     "start_time": "2024-06-28T16:28:00.833969900Z"
    }
   },
   "id": "686b105f31257147",
   "execution_count": 206
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, activations):\n",
    "    cache = {}\n",
    "    A = X\n",
    "    cache['A0'] = A\n",
    "    L = len(parameters) // 2  # Number of layers\n",
    "\n",
    "    for l in range(1, L + 1):\n",
    "        A_prev = A\n",
    "        W = parameters['W' + str(l)]\n",
    "        b = parameters['b' + str(l)]\n",
    "        Z = np.dot(W, A_prev) + b\n",
    "        if activations[l-1] == 'relu':\n",
    "            A = relu(Z)\n",
    "        elif activations[l-1] == 'softmax':\n",
    "            A = softmax(Z)\n",
    "        elif activations[l-1] == 'sigmoid':\n",
    "            A = sigmoid(Z)\n",
    "\n",
    "        cache['A' + str(l)] = A\n",
    "        cache['Z' + str(l)] = Z\n",
    "        cache['W' + str(l)] = W\n",
    "        cache['b' + str(l)] = b\n",
    "\n",
    "    return A, cache"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T16:25:17.750347300Z",
     "start_time": "2024-06-28T16:25:17.745162Z"
    }
   },
   "id": "3d6a17f3dfa96033",
   "execution_count": 195
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def relu_derivative(z):\n",
    "    return np.array(z > 0)\n",
    "\n",
    "def softmax_derivative(softmax_output):\n",
    "    s = softmax_output.reshape(-1, 1)\n",
    "    jacobian_matrix = np.diagflat(s) - np.dot(s, s.T)\n",
    "    return jacobian_matrix\n",
    "\n",
    "def loss_function_derivative(y,s):\n",
    "    return y/s\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T16:22:39.255623100Z",
     "start_time": "2024-06-28T16:22:39.249084300Z"
    }
   },
   "id": "392bfe93cd19cf6c",
   "execution_count": 188
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Back Propagation\n",
    "\n",
    "The back_propagation function calculates the gradients of the loss function with respect to the weights and biases of a deep neural network using the chain rule of calculus. This process is essential for updating the network's parameters during training. The function takes the predicted output AL, the true labels y, the cache containing intermediate values from forward propagation, and the list of activation functions used in each layer. It initializes an empty dictionary gradients to store the calculated gradients. The function iterates backward from the output layer to the first hidden layer. For each layer, it computes the gradient of the loss with respect to the activations (dZ), the weights (dW), and the biases (db). The computation involves matrix multiplications and applying the derivatives of the activation functions (ReLU and Softmax in this case). These gradients are used to adjust the weights and biases to minimize the loss during the optimization step, allowing the network to learn from the data. The function finally returns the gradients dictionary containing the necessary gradients for updating the network's parameters."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "158efd77c11da8a1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def back_propagation(AL, y, cache, activations):\n",
    "    gradients = {}\n",
    "    L = len(cache) // 4 \n",
    "    m = y.shape[1]\n",
    "\n",
    "    # gradients[\"dZ\"+ str(L)] = np.dot(loss_function_derivative(y,AL),softmax_derivative(AL))\n",
    "    gradients[\"dZ\"+ str(L)] = AL - y # derivative of loss function wrt zL\n",
    "    gradients[\"dW\"+ str(L)] = np.dot(gradients[\"dZ\"+ str(L)],cache[\"A\" + str(L-1)].T) / m\n",
    "    gradients[\"db\" + str(L)] = np.sum(gradients[\"dZ\"+ str(L)], axis=1, keepdims=True) / m\n",
    "    for l in reversed(range(1, L)):\n",
    "        if activations[l-1] == 'softmax':\n",
    "            gradients[\"dZ\"+ str(l)] = np.dot(cache[\"W\" + str(l+1)].T,gradients[\"dZ\"+ str(l+1)]) * softmax_derivative(cache[\"Z\"+ str(l)])\n",
    "        elif activations[l-1] == 'relu':\n",
    "            gradients[\"dZ\"+ str(l)] = np.dot(cache[\"W\" + str(l+1)].T,gradients[\"dZ\"+ str(l+1)]) * relu_derivative(cache[\"Z\"+ str(l)])\n",
    "        \n",
    "        gradients[\"dW\"+ str(l)] = np.dot(gradients[\"dZ\"+ str(l)],cache[\"A\" + str(l-1)].T) / m\n",
    "        gradients[\"db\" + str(l)] = np.sum(gradients[\"dZ\"+ str(l)], axis=1, keepdims=True) / m\n",
    "\n",
    "    return gradients\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T13:04:34.355967600Z",
     "start_time": "2024-06-27T13:04:34.346882400Z"
    }
   },
   "id": "4d416b4543337c43",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def update_parameters(parameters, gradients, learning_rate):\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(1, L + 1):\n",
    "        parameters['W' + str(l)] -= learning_rate * gradients['dW' + str(l)]\n",
    "        parameters['b' + str(l)] -= learning_rate * gradients['db' + str(l)]\n",
    "    return parameters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T12:56:04.728274500Z",
     "start_time": "2024-06-27T12:56:04.719296300Z"
    }
   },
   "id": "8f5ec1332237f658",
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utility Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b88ebe7d09a9a058"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_accuracy(pred, y):\n",
    "    return np.sum(pred == y) / y.size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T12:37:07.982805500Z",
     "start_time": "2024-06-27T12:37:07.973482900Z"
    }
   },
   "id": "9165ca25c2056477",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def binary_prediction(a2):\n",
    "    return np.where(a2 > 0.5, 1, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T16:38:19.512165700Z",
     "start_time": "2024-06-28T16:38:19.496686700Z"
    }
   },
   "id": "d4565b5d08643dda",
   "execution_count": 216
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_predictions(a2):\n",
    "    return np.argmax(a2, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T19:40:24.300562Z",
     "start_time": "2024-06-28T19:40:24.276908900Z"
    }
   },
   "id": "fde19388f9adb92",
   "execution_count": 270
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test_preds(x_train, parameters,y):\n",
    "    A, cache = forward_propagation(x_train,parameters,activations)\n",
    "    preds = get_predictions(A)\n",
    "    accuracy = get_accuracy(preds, y)\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T12:37:10.102767300Z",
     "start_time": "2024-06-27T12:37:10.093789700Z"
    }
   },
   "id": "1ae1add2812d6afb",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def one_hot(y, num_classes):\n",
    "    return np.eye(num_classes)[y].T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T12:37:11.711379900Z",
     "start_time": "2024-06-27T12:37:11.700376700Z"
    }
   },
   "id": "9511e6f1aa061cb7",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "layer_dims = [input_size, 50, output_size]\n",
    "activations = [\"relu\", \"softmax\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T20:07:40.321819500Z",
     "start_time": "2024-06-28T20:07:40.302725800Z"
    }
   },
   "id": "38022c613edb172e",
   "execution_count": 293
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def L_layer_model(x_train,y_train,x_test,y_test, learning_rate, num_iterations,classification_type=\"multiclass\"):\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    y_train_one_hot = one_hot(y_train, num_classes)\n",
    "    for epoch in range(num_iterations):\n",
    "        AL, cache = forward_propagation(x_train, parameters, activations)\n",
    "        if classification_type == \"multiclass\":\n",
    "            loss = loss_function(AL, y_train_one_hot)\n",
    "            gradients = back_propagation(AL, y_train_one_hot, cache, activations)\n",
    "            parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "            preds_train = get_predictions(AL)\n",
    "            accuracy_train = get_accuracy(preds_train, y_train)\n",
    "            accuracy_test = test_preds(x_test, parameters, y_test)\n",
    "        elif classification_type == \"binaryclass\":\n",
    "            loss = binary_cross_entropy_loss(AL, y_train)\n",
    "            gradients = back_propagation(AL, y_train, cache, activations)\n",
    "            parameters = update_parameters(parameters, gradients, 0.06)\n",
    "            preds_train = binary_prediction(AL)\n",
    "            accuracy_train = get_accuracy(preds_train, y_train)\n",
    "            accuracy_test = test_preds(x_test, parameters, y_test)\n",
    "        else:\n",
    "            print(\"multiclass or binaryclass clasification!\")\n",
    "            break\n",
    "        if (epoch % 50 == 0) | (epoch == num_iterations - 1):\n",
    "            print(f\"Epoch {epoch+1} - Train Accuracy: {accuracy_train:.4f} - Cost: {loss:.4f}\")\n",
    "            print(f\"Test Accuracy: {accuracy_test:.4f}\")\n",
    "    return parameters\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T20:08:20.809067700Z",
     "start_time": "2024-06-28T20:08:20.778290400Z"
    }
   },
   "id": "3ffd0af612325621",
   "execution_count": 296
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68a68b67c81050e4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Accuracy: 0.0661 - Cost: 2.3033\n",
      "Test Accuracy: 0.1026\n",
      "Epoch 51 - Train Accuracy: 0.4377 - Cost: 2.1341\n",
      "Test Accuracy: 0.4376\n",
      "Epoch 101 - Train Accuracy: 0.7491 - Cost: 1.0911\n",
      "Test Accuracy: 0.7576\n",
      "Epoch 151 - Train Accuracy: 0.8233 - Cost: 0.6853\n",
      "Test Accuracy: 0.8286\n",
      "Epoch 201 - Train Accuracy: 0.8574 - Cost: 0.5428\n",
      "Test Accuracy: 0.8598\n",
      "Epoch 251 - Train Accuracy: 0.8744 - Cost: 0.4706\n",
      "Test Accuracy: 0.8756\n",
      "Epoch 301 - Train Accuracy: 0.8841 - Cost: 0.4266\n",
      "Test Accuracy: 0.8849\n",
      "Epoch 351 - Train Accuracy: 0.8898 - Cost: 0.3966\n",
      "Test Accuracy: 0.8913\n",
      "Epoch 401 - Train Accuracy: 0.8951 - Cost: 0.3746\n",
      "Test Accuracy: 0.8965\n",
      "Epoch 451 - Train Accuracy: 0.8993 - Cost: 0.3577\n",
      "Test Accuracy: 0.9019\n",
      "Epoch 500 - Train Accuracy: 0.9025 - Cost: 0.3445\n",
      "Test Accuracy: 0.9042\n"
     ]
    }
   ],
   "source": [
    "params = L_layer_model(x_train,y_train,x_test,y_test, 0.1, 500)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T20:11:35.510462500Z",
     "start_time": "2024-06-28T20:08:21.925112300Z"
    }
   },
   "id": "ac391637bb888b13",
   "execution_count": 297
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def make_preds(i,parameters,activations,image):\n",
    "    AL,_ = forward_propagation(x_test[:,i].reshape(-1, 1),parameters,activations)\n",
    "    preds_t = get_predictions(AL)\n",
    "    print(preds_t)\n",
    "    print(y_test[i])\n",
    "    if image:\n",
    "        image = x_test[:, i].reshape(-1, 1)\n",
    "        plt.gray()\n",
    "        plt.imshow(image, interpolation='nearest')\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T19:44:16.575719800Z",
     "start_time": "2024-06-28T19:44:16.554198200Z"
    }
   },
   "id": "821e1b0043514fac",
   "execution_count": 275
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "make_preds(800,params,activations,False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-28T19:44:56.801808900Z",
     "start_time": "2024-06-28T19:44:56.764758900Z"
    }
   },
   "id": "8f805e8403937efc",
   "execution_count": 283
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
